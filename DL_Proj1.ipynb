{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import dlc_practical_prologue as prologue\n",
    "%matplotlib inline\n",
    "N=1000\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompareNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CompareNet, self).__init__()\n",
    "        self.base = nn.Sequential(nn.Linear(196,64),nn.ReLU(),nn.Linear(64,32))\n",
    "        self.comparator = nn.Linear(64,2)\n",
    "        self.classifier = nn.Linear(32,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_0 = x[:,0,:,:].flatten(1)\n",
    "        x_1 = x[:,1,:,:].flatten(1)\n",
    "        x_0 = F.relu(self.base(x_0))\n",
    "        x_1 = F.relu(self.base(x_1))\n",
    "        sign = F.relu(self.comparator(torch.cat([x_0,x_1],dim = 1)))\n",
    "        digit_0 = F.relu(self.classifier(x_0))\n",
    "        digit_1 = F.relu(self.classifier(x_1))\n",
    "        return sign, digit_0, digit_1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitPairsDataset(Dataset):\n",
    "    def __init__(self,img_pair,targets, classes):\n",
    "        super(DigitPairsDataset, self).__init__()\n",
    "        self.img_pair = img_pair\n",
    "        self.targets = targets\n",
    "        self.classes = classes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.targets.size()[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.img_pair[idx], self.targets[idx], self.classes[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CompareNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "mu = 1.0\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.001)\n",
    "train_dataset = DigitPairsDataset(train_input,train_target,train_classes)\n",
    "test_dataset = DigitPairsDataset(test_input,test_target,test_classes)\n",
    "train_loader = DataLoader(train_dataset,batch_size=32, shuffle = True, num_workers = 4)\n",
    "test_loader = DataLoader(test_dataset,batch_size=32, shuffle = True, num_workers = 4)\n",
    "\n",
    "def calc_accuracy(data_loader,model):\n",
    "    correct_count = 0.0\n",
    "    for i, data in enumerate(data_loader,0):\n",
    "        img_pair, target, classes = data\n",
    "        pred_sign, pred_class0, pred_class1 = model(img_pair)\n",
    "        pred = torch.argmax(pred_sign,-1)\n",
    "        correct_count += int((target.eq(pred)).sum())\n",
    "    return correct_count*100.0/N\n",
    "\n",
    "epochs = 200\n",
    "loss_arr = []\n",
    "train_acc_arr = []\n",
    "val_acc_arr = []\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        img_pair, target, classes = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_sign, pred_class0, pred_class1 = net(img_pair)\n",
    "        loss = criterion(pred_sign,target)+ mu*(criterion(pred_class0, classes[:,0])+ criterion(pred_class1, classes[:,1]))\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    net.eval()\n",
    "    running_loss /= N\n",
    "    loss_arr.append(running_loss)\n",
    "    train_acc = calc_accuracy(train_loader,net)\n",
    "    val_acc = calc_accuracy(test_loader,net)\n",
    "    train_acc_arr.append(train_acc)\n",
    "    val_acc_arr.append(val_acc)\n",
    "    print(\"Epoch : %d  ,   Train Accuracy : %.5f  , Validation Accuracy : %.5f , Training Loss : %.6f\" %(epoch, train_acc, val_acc, running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
