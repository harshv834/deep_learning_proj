{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "” using only pytorch’s\n",
    "tensor operations and the standard math library\n",
    "\n",
    "Your framework should import only torch.empty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fecca2871d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import empty\n",
    "import math\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(False) #turns off autograd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your framework must provide the necessary tools to:\n",
    " build networks combining fully connected layers, Tanh, and ReLU,\n",
    " run the forward and backward passes,\n",
    " optimize parameters with SGD for MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must implement a test executable named test.py that imports your framework and\n",
    " Generates a training and a test set of 1, 000 points sampled uniformly in [0, 1]2\n",
    ", each with a\n",
    "label 0 if outside the disk centered at (0.5, 0.5) of radius 1/\n",
    "√\n",
    "2π, and 1 inside,\n",
    " builds a network with two input units, two output units, three hidden layers of 25 units,\n",
    " trains it with MSE, logging the loss,\n",
    " computes and prints the final train and the test errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Structure is better if original\n",
    "\n",
    "class Module ( object ) :\n",
    "\n",
    "    def forward ( self , * input ) :\n",
    "        raise NotImplementedError\n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "    def param ( self ) :\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter(object):\n",
    "    def __init__(self, data, grad=None, x=None,update = True ):\n",
    "        super(Parameter, self).__init__()\n",
    "        self.update = True\n",
    "        self.data = data\n",
    "        self.grad = grad\n",
    "        self.input = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lossMSE(Module):\n",
    "    def __init__(self):\n",
    "        super(lossMSE, self).__init__()\n",
    "        self.name = 'MSE_loss'\n",
    "    def forward(self, input, target):\n",
    "        return input.sub(target).pow(2).mean() \n",
    "    def backward(self, input, target):\n",
    "        return input.sub(target.view(-1,input.shape[1])).mul(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        super(ReLU, self).__init__()\n",
    "        self.name = 'ReLU'\n",
    "        self.params = Parameter(None,update = False)\n",
    "    def forward(self, input):\n",
    "        self.params.input = input\n",
    "        return input.clamp(min = 0)\n",
    "    def backward(self, gradwrtoutput):\n",
    "        self.params.grad =  self.params.input.sign().add(1).div(2) * gradwrtoutput\n",
    "        return self.params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self,x = None):\n",
    "        super(Tanh,self).__init__()\n",
    "        self.name = 'Tanh'\n",
    "        self.params = Parameter(None, update = False)\n",
    "    def forward(self, input):\n",
    "        self.params.input = input\n",
    "        return input.tanh()\n",
    "    def backward(self, gradwrtoutput):\n",
    "        self.params.grad = (1 - self.param.input.tanh().pow(2) ).mul(gradwrtoutput)\n",
    "        return self.params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self,in_dim, out_dim,init='zero'):\n",
    "        self.params = Parameter(torch.zeros((in_dim,out_dim)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.params.input = x\n",
    "        return  x @self.params.data\n",
    "    \n",
    "    def backward(self, gradwrtoutput):\n",
    "        self.params.grad = gradwrtoutput.mul(self.params.input)\n",
    "        return self.params.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(Module):\n",
    "    def __init__(self, modules):\n",
    "        super(Sequential, self).__init__()\n",
    "        self.modules = modules\n",
    "        self.params = []\n",
    "        for mod in self.modules:\n",
    "            if mod.param() is not None:\n",
    "                self.params.append(mod.param())\n",
    "        \n",
    "            \n",
    "    def forward(self, input):\n",
    "        for mod in self.modules:\n",
    "            input = mod.forward(input)\n",
    "        return input\n",
    "    \n",
    "    def backward(self, gradwrtoutput):\n",
    "        for mod in reversed(self.modules):\n",
    "            gradwrtoutput = mod.backward(gradwrtoutput)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD_opti(object):\n",
    "    def __init__(self, model_parameters, learn_rate = 1e-3):\n",
    "        self.lr = learn_rate\n",
    "        self.param_to_update = model_parameters\n",
    "    \n",
    "    def step(self):\n",
    "        for ind_module in self.param_to_update:\n",
    "            if len(ind_module) > 0:\n",
    "                for p in ind_module:\n",
    "                    if p.update:\n",
    "                        p.data -= self.lr*p.grad\n",
    "                    \n",
    "    def zero_grad(self):\n",
    "        for ind_module in self.param_to_update:\n",
    "            if len(ind_module) >0 :\n",
    "                for p in ind_module:\n",
    "                    p.input = None\n",
    "                    p.grad = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_disc_set(nb):\n",
    "    data = empty(nb,2).uniform_(0,1)\n",
    "    target = (data-0.5).pow(2).sum(1).sub(2/math.pi).sign().add(1).div(2)\n",
    "    \n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot_labels(target):\n",
    "    hot_labels = empty(target.size(0), 2)\n",
    "    hot_labels[:,0], hot_labels[:,1] = 1-target, target \n",
    "    return hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Linear(2,10), ReLU()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = SGD_opti(model.param())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,target = generate_disc_set(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Generates a training and a test set of 1, 000 points sampled uniformly in [0, 1]2\n",
    ", each with a\n",
    "label 0 if outside the disk centered at (0.5, 0.5) of radius 1/\n",
    "√\n",
    "2π, and 1 inside,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def generate_disk_set(nb):\n",
    "    input = Tensor(nb, 1).uniform_(0, 1)\n",
    "    target = input.pow(2).sum(1).sub(1 / math.pi).sign().add(1).div(2).long()\n",
    "    return input, target\n",
    "\n",
    "train_input, train_target = generate_disc_set(1000)\n",
    "test_input, test_target = generate_disc_set(1000)\n",
    "\n",
    "mean, std = train_input.mean(), train_input.std()\n",
    "\n",
    "train_input.sub_(mean).div_(std)\n",
    "test_input.sub_(mean).div_(std)\n",
    "\n",
    "mini_batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " builds a network with two input units, two output units, three hidden layers of 25 units\n",
    "\n",
    "that returns a mlp with 2 input units, hidden layers of sizes respectively 4, 8, 16, 32, 64, 128, and 2\n",
    "output units\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_shallow_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(2, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 2)\n",
    "    )\n",
    "\n",
    "def create_deep_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(2, 4),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward and backward ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def forward_pass(w1, b1, w2, b2, x):\n",
    "    x0 = x\n",
    "    s1 = w1.mv(x0) + b1\n",
    "    x1 = sigma(s1)\n",
    "    s2 = w2.mv(x1) + b2\n",
    "    x2 = sigma(s2)\n",
    "\n",
    "    return x0, s1, x1, s2, x2\n",
    "\n",
    "def backward_pass(w1, b1, w2, b2,\n",
    "                  t,\n",
    "                  x, s1, x1, s2, x2,\n",
    "                  dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
    "    x0 = x\n",
    "    dl_dx2 = dloss(x2, t)\n",
    "    dl_ds2 = dsigma(s2) * dl_dx2\n",
    "    dl_dx1 = w2.t().mv(dl_ds2)\n",
    "    dl_ds1 = dsigma(s1) * dl_dx1\n",
    "\n",
    "    dl_dw2.add_(dl_ds2.view(-1, 1).mm(x1.view(1, -1)))\n",
    "    dl_db2.add_(dl_ds2)\n",
    "    dl_dw1.add_(dl_ds1.view(-1, 1).mm(x0.view(1, -1)))\n",
    "    dl_db1.add_(dl_ds1)\n",
    "    \n",
    "    #ensuite utilisé dans la partie 4 de practical 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
